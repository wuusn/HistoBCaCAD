{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from rl_benchmarks.models import iBOTViT\n",
    "from openslide import open_slide\n",
    "from openslide.deepzoom import DeepZoomGenerator\n",
    "import pathlib\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "Image.MAX_IMAGE_PIXELS = None\n",
    "from torchvision import transforms\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import os\n",
    "from multiprocessing import Pool\n",
    "import umap\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from rl_benchmarks.utils.linear_evaluation import get_binary_class_metrics, get_bootstrapped_metrics\n",
    "\n",
    "from PIL import Image\n",
    "import pathlib\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "Image.MAX_IMAGE_PIXELS = None\n",
    "from torchvision import transforms\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import os\n",
    "from multiprocessing import Pool\n",
    "# import umap\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision import transforms\n",
    "\n",
    "from sklearn.metrics import f1_score, precision_recall_fscore_support, roc_auc_score, confusion_matrix, cohen_kappa_score, accuracy_score\n",
    "import torch.nn.functional as F\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "# import albumentations as A\n",
    "# from albumentations.pytorch import ToTensorV2\n",
    "import cv2\n",
    "import time\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "import timm\n",
    "from metrics import report\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader, Subset, Dataset\n",
    "from tqdm import tqdm\n",
    "from rl_benchmarks.metrics import *\n",
    "\n",
    "from rl_benchmarks.trainers.torch_trainer import TorchTrainer\n",
    "from rl_benchmarks.models.slide_models.meanpool import MeanPool\n",
    "from rl_benchmarks.models.slide_models.chowder import Chowder\n",
    "from rl_benchmarks.models.slide_models.dsmil import DSMIL\n",
    "from rl_benchmarks.models.slide_models.abmil import ABMIL\n",
    "from rl_benchmarks.models.slide_models.hiptmil import HIPTMIL\n",
    "from rl_benchmarks.models.slide_models.transmil import TransMIL\n",
    "\n",
    "from pathlib import Path\n",
    "from metrics import report\n",
    "\n",
    "import sys\n",
    "sys.path.append('/home/yuxin/bme/BCaCAD/model')\n",
    "from patch_based_test.img import QiLuROI\n",
    "\n",
    "def get_model(model_name, in_dim, out_dim):\n",
    "    if model_name == 'abmil':\n",
    "        model = ABMIL(in_dim, out_dim, d_model_attention=128,temperature= 1.0, mlp_hidden= [128, 64])\n",
    "    elif model_name == 'chowder':\n",
    "        model = Chowder(in_dim, out_dim, n_top= 2,n_bottom= 2,tiles_mlp_hidden= [128], mlp_hidden= [128, 64])\n",
    "    elif model_name == 'dsmil':\n",
    "        model = DSMIL(in_dim, out_dim, d_tiles_values= 32,d_tiles_queries= 32,passing_values= False,tiles_scores_mlp_hidden=[200,100],\n",
    "                        tiles_queries_mlp_hidden=[200,100], mlp_hidden=[200,100])\n",
    "    elif model_name == 'hiptmil':\n",
    "        model = HIPTMIL(in_dim, out_dim)\n",
    "    elif model_name == 'transmil':\n",
    "        model = TransMIL(in_dim, out_features=out_dim)\n",
    "    elif model_name == 'meanpool':\n",
    "        model = MeanPool(in_dim, out_dim)\n",
    "    else:\n",
    "        raise 'model not found'\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IBOTMultiTaskModel(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(IBOTMultiTaskModel, self).__init__()\n",
    "        weights_path = '/home/yuxin/Downloads/ibot_vit_base_pancan.pth'\n",
    "        self.base_model = iBOTViT(architecture=\"vit_base_pancan\", encoder=\"teacher\", weights_path=weights_path)\n",
    "        # print(self.base_model)\n",
    "        self.num_features = 768\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        if isinstance(num_classes, list):\n",
    "            self.heads = nn.ModuleList([nn.Linear(self.num_features, num_class) for num_class in num_classes])\n",
    "        else:\n",
    "            self.head = self.base_model.head\n",
    "            self.head.fc = nn.Linear(self.num_features, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Forward pass through the base model\n",
    "        x = self.base_model(x)\n",
    "        if isinstance(self.num_classes, list):\n",
    "            x = [head(x) for head in self.heads]\n",
    "        else:\n",
    "            x = self.head(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "num_classes = [3,3]\n",
    "img_size = patch_size = 384\n",
    "data_trans = {\n",
    "    \"train\": transforms.Compose([\n",
    "                                transforms.Resize(img_size),\n",
    "                                transforms.ColorJitter(),\n",
    "                                transforms.RandomHorizontalFlip(),\n",
    "                                transforms.RandomVerticalFlip(),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])]),\n",
    "    \"test\": transforms.Compose([\n",
    "                                transforms.Resize((img_size,img_size)),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-04-01 09:14:59.258\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrl_benchmarks.models.feature_extractors.ibot_vit\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m78\u001b[0m - \u001b[1mPretrained weights found at /home/yuxin/Downloads/ibot_vit_base_pancan.pth and loaded with msg: _IncompatibleKeys(missing_keys=[], unexpected_keys=['head.mlp.0.weight', 'head.mlp.0.bias', 'head.mlp.2.weight', 'head.mlp.2.bias', 'head.mlp.4.weight', 'head.mlp.4.bias', 'head.last_layer.weight_g', 'head.last_layer.weight_v', 'head.last_layer2.weight_g', 'head.last_layer2.weight_v'])\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_model = IBOTMultiTaskModel(num_classes)\n",
    "device = \"cuda\"\n",
    "feature_model.to(device)\n",
    "feature_model = nn.DataParallel(feature_model)\n",
    "weight_path = '/mnt/hd0/project/bcacad/model/pretrainSSL_ibot_vit+ibot_ft+fsl_ft/model-5.pth'\n",
    "feature_model.load_state_dict(torch.load(weight_path, map_location=device)['model_state_dict'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Feature_Fly(Dataset):\n",
    "    def get_label(self, type):\n",
    "        D = {\n",
    "            'normal':[0,0],\n",
    "            'dcis-1':[1,0],\n",
    "            'dcis-2':[1,1],\n",
    "            'dcis-3':[1,2],\n",
    "            'ibc-1':[2,0],\n",
    "            'ibc-2':[2,1],\n",
    "            'ibc-3':[2,2],\n",
    "        }\n",
    "        label =  D[type]\n",
    "        return label[0],label[1]\n",
    "    \n",
    "    def __init__(self, image_dir, phase='test', train_tile=None):\n",
    "        folder = Path(image_dir)\n",
    "        self.im_paths = list(folder.rglob('**/*.*'))\n",
    "        self.labels = [self.get_label(path.parent.name) for path in self.im_paths]\n",
    "        self.phase=phase\n",
    "        self.train_tile = train_tile\n",
    "        self.size = 336\n",
    "        self.bs = 16\n",
    "        self.src_mag = 10\n",
    "        self.tar_mag = 10\n",
    "    \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.im_paths)\n",
    "    def __getitem__(self, item):\n",
    "        im_path = self.im_paths[item]\n",
    "        im = QiLuROI(str(im_path), self.src_mag, self.tar_mag, self.size)\n",
    "        im.setIterator(self.size)\n",
    "        patches = [p for p in im]\n",
    "        if self.phase == 'train':\n",
    "            indices = np.random.choice(len(patches), self.train_tile, replace=True)\n",
    "            patches = [patches[i] for i in indices]\n",
    "        patches = [data_trans[self.phase](p) for p in patches]\n",
    "        bs = self.bs\n",
    "        for i in range(0, len(patches), bs):\n",
    "            x = torch.stack(patches[i:i+bs], dim=0)\n",
    "            x = x.to(device)\n",
    "            y = feature_model.module.base_model(x)\n",
    "            if i == 0:\n",
    "                features = y#.detach().cpu().numpy()\n",
    "            else:\n",
    "                features = torch.concatenate([features, y], dim=0)\n",
    "                #np.concatenate([features, y.detach().cpu().numpy()], axis=0)\n",
    "        return features, self.labels[item]\n",
    "    \n",
    "    @staticmethod\n",
    "    def collate_fn(batch):\n",
    "        # 官方实现的default_collate可以参考\n",
    "        # https://github.com/pytorch/pytorch/blob/67b7e751e6b5931a9f45274653f4f653a4e6cdf6/torch/utils/data/_utils/collate.py\n",
    "        images,  labels = tuple(zip(*batch))\n",
    "\n",
    "        images = torch.stack(images, dim=0)\n",
    "        labels = torch.as_tensor(labels)\n",
    "        # masks = torch.as_tensor(masks)\n",
    "\n",
    "        return images, labels\n",
    "\n",
    "class Feature(Dataset):\n",
    "    def get_label(self, type):\n",
    "        D = {\n",
    "            'normal':[0,0],\n",
    "            'dcis-1':[1,0],\n",
    "            'dcis-2':[1,1],\n",
    "            'dcis-3':[1,2],\n",
    "            'ibc-1':[2,0],\n",
    "            'ibc-2':[2,1],\n",
    "            'ibc-3':[2,2],\n",
    "        }\n",
    "        label =  D[type]\n",
    "        return label[0],label[1]\n",
    "    \n",
    "    def __init__(self, feature_dir, phase='test'):\n",
    "        folder = Path(feature_dir)\n",
    "        feature_paths = list(folder.rglob('**/*.npy'))\n",
    "        self.labels = [self.get_label(path.parent.name) for path in feature_paths]\n",
    "        self.features = [np.load(path) for path in feature_paths]\n",
    "        self.phase=phase\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "    def __getitem__(self, item):\n",
    "        features = self.features[item]\n",
    "        if self.phase == 'train':\n",
    "            indices = np.random.choice(features.shape[0], 8, replace=True)\n",
    "            features = np.stack([features[i] for i in indices], axis=0)\n",
    "        return features, self.labels[item]\n",
    "    \n",
    "    @staticmethod\n",
    "    def collate_fn(batch):\n",
    "        # 官方实现的default_collate可以参考\n",
    "        # https://github.com/pytorch/pytorch/blob/67b7e751e6b5931a9f45274653f4f653a4e6cdf6/torch/utils/data/_utils/collate.py\n",
    "        images,  labels = tuple(zip(*batch))\n",
    "\n",
    "        images = torch.stack(images, dim=0)\n",
    "        labels = torch.as_tensor(labels)\n",
    "        # masks = torch.as_tensor(masks)\n",
    "\n",
    "        return images, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = dict(\n",
    "    epoch=2,\n",
    "    bs=8,\n",
    "    train_tiles = 4,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root = Path('/mnt/hd0/project/bcacad/data/roi-level')\n",
    "feature_root = Path('/mnt/hd0/project/bcacad/model/roi_features')\n",
    "test_cohorts = ['suqh_all_patch', 'qduh', 'shsu', 'bracs', 'bcnb', 'bach', 'apght']\n",
    "# test_cohorts = ['suqh_all_patch']\n",
    "train_set = Feature_Fly(data_root / 'suqh' / 'model', 'train', cfg['train_tiles'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 768])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "merics = {'acc': compute_multiclass_accuracy, 'auc': compute_mean_one_vs_all_auc}\n",
    "input_dim = 768\n",
    "out_dim = [3,3]\n",
    "tasks = ['type', 'nonibc', 'ibc']\n",
    "class_names = {\n",
    "    'type': ['Normal', 'nonIBC', 'IBC'],\n",
    "    'nonibc': ['Low', 'Medium', 'High'],\n",
    "    'ibc': ['Low', 'Medium', 'High'],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:19<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m model \u001b[38;5;241m=\u001b[39m get_model(model_name, input_dim, out_dim)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      7\u001b[0m trainer \u001b[38;5;241m=\u001b[39m TorchTrainer(model, criterion, merics, device\u001b[38;5;241m=\u001b[39mdevice, num_epochs\u001b[38;5;241m=\u001b[39mcfg[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepoch\u001b[39m\u001b[38;5;124m'\u001b[39m], batch_size\u001b[38;5;241m=\u001b[39mcfg[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbs\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m----> 8\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_set\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_set\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# res = trainer.train(fake, fake)\u001b[39;00m\n\u001b[1;32m     10\u001b[0m models[model_name] \u001b[38;5;241m=\u001b[39m model\n",
      "File \u001b[0;32m~/bme/BCaCAD/model/HistoSSLscaling/rl_benchmarks/trainers/torch_trainer.py:168\u001b[0m, in \u001b[0;36mTorchTrainer.train\u001b[0;34m(self, train_set, val_set)\u001b[0m\n\u001b[1;32m    156\u001b[0m loop \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    157\u001b[0m     tqdm(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_epochs), total\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_epochs)\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_tqdm\n\u001b[1;32m    159\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_epochs)\n\u001b[1;32m    160\u001b[0m )\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m loop:\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;66;03m# Train step.\u001b[39;00m\n\u001b[1;32m    163\u001b[0m     (\n\u001b[1;32m    164\u001b[0m         train_epoch_loss,\n\u001b[1;32m    165\u001b[0m         train_epoch_logits,\n\u001b[1;32m    166\u001b[0m         train_epoch_preds,\n\u001b[1;32m    167\u001b[0m         train_epoch_labels,\n\u001b[0;32m--> 168\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    169\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    174\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_step\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgc_step\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    177\u001b[0m     \u001b[38;5;66;03m# Inference step.\u001b[39;00m\n\u001b[1;32m    178\u001b[0m     val_epoch_loss, val_epoch_logits, val_epoch_preds, val_epoch_labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mval_step(\n\u001b[1;32m    179\u001b[0m         model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m    180\u001b[0m         val_dataloader\u001b[38;5;241m=\u001b[39mval_dataloader,\n\u001b[1;32m    181\u001b[0m         criterion\u001b[38;5;241m=\u001b[39mcriterion,\n\u001b[1;32m    182\u001b[0m         device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice,\n\u001b[1;32m    183\u001b[0m     )\n",
      "File \u001b[0;32m~/bme/BCaCAD/model/HistoSSLscaling/rl_benchmarks/trainers/utils.py:45\u001b[0m, in \u001b[0;36mslide_level_train_step\u001b[0;34m(model, train_dataloader, criterion, optimizer, device, gc_step)\u001b[0m\n\u001b[1;32m     41\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m     43\u001b[0m _epoch_loss, _epoch_logits, _epoch_preds, _epoch_labels \u001b[38;5;241m=\u001b[39m [], [[],[]], [[],[]], [[],[]]\n\u001b[0;32m---> 45\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, batch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_dataloader):\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;66;03m# Get data.\u001b[39;00m\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;66;03m# features, mask, labels = batch\u001b[39;00m\n\u001b[1;32m     48\u001b[0m     features, labels \u001b[38;5;241m=\u001b[39m batch\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;66;03m# Put on device.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/histosslscaling/lib/python3.8/site-packages/torch/utils/data/dataloader.py:628\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    625\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    626\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    627\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 628\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    629\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    631\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    632\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/miniconda3/envs/histosslscaling/lib/python3.8/site-packages/torch/utils/data/dataloader.py:671\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    669\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    670\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 671\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    672\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    673\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/miniconda3/envs/histosslscaling/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py:58\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     56\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 58\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     60\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/miniconda3/envs/histosslscaling/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py:58\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     56\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 58\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     60\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[0;32mIn[5], line 33\u001b[0m, in \u001b[0;36mFeature_Fly.__getitem__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m     31\u001b[0m im \u001b[38;5;241m=\u001b[39m QiLuROI(\u001b[38;5;28mstr\u001b[39m(im_path), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msrc_mag, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtar_mag, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msize)\n\u001b[1;32m     32\u001b[0m im\u001b[38;5;241m.\u001b[39msetIterator(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msize)\n\u001b[0;32m---> 33\u001b[0m patches \u001b[38;5;241m=\u001b[39m [p \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m im]\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mphase \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m     35\u001b[0m     indices \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mchoice(\u001b[38;5;28mlen\u001b[39m(patches), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_tile, replace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[5], line 33\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     31\u001b[0m im \u001b[38;5;241m=\u001b[39m QiLuROI(\u001b[38;5;28mstr\u001b[39m(im_path), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msrc_mag, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtar_mag, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msize)\n\u001b[1;32m     32\u001b[0m im\u001b[38;5;241m.\u001b[39msetIterator(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msize)\n\u001b[0;32m---> 33\u001b[0m patches \u001b[38;5;241m=\u001b[39m [p \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m im]\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mphase \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m     35\u001b[0m     indices \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mchoice(\u001b[38;5;28mlen\u001b[39m(patches), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_tile, replace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/bme/BCaCAD/model/patch_based_test/img.py:121\u001b[0m, in \u001b[0;36mAbstractImage.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__next__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m#return self.iteratorSimple()\u001b[39;00m\n\u001b[0;32m--> 121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miteratorAll\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/bme/BCaCAD/model/patch_based_test/img.py:155\u001b[0m, in \u001b[0;36mAbstractImage.iteratorAll\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    153\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mX\n\u001b[1;32m    154\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpatchYStride\n\u001b[0;32m--> 155\u001b[0m patch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetRegion\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtmpX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtmpY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpatchW\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpatchH\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m patch\n",
      "File \u001b[0;32m~/bme/BCaCAD/model/patch_based_test/img.py:229\u001b[0m, in \u001b[0;36mROI.getRegion\u001b[0;34m(self, x, y, w, h)\u001b[0m\n\u001b[1;32m    227\u001b[0m W \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(W)\n\u001b[1;32m    228\u001b[0m H \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(H)\n\u001b[0;32m--> 229\u001b[0m roi \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mW\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mH\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    230\u001b[0m roi \u001b[38;5;241m=\u001b[39m roi\u001b[38;5;241m.\u001b[39mresize((w, h), Image\u001b[38;5;241m.\u001b[39mBICUBIC)\n\u001b[1;32m    231\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m roi\n",
      "File \u001b[0;32m~/miniconda3/envs/histosslscaling/lib/python3.8/site-packages/PIL/Image.py:1206\u001b[0m, in \u001b[0;36mImage.crop\u001b[0;34m(self, box)\u001b[0m\n\u001b[1;32m   1203\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCoordinate \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlower\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is less than \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mupper\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1204\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[0;32m-> 1206\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1207\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_new(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_crop(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mim, box))\n",
      "File \u001b[0;32m~/miniconda3/envs/histosslscaling/lib/python3.8/site-packages/PIL/ImageFile.py:249\u001b[0m, in \u001b[0;36mImageFile.load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    248\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 249\u001b[0m         s \u001b[38;5;241m=\u001b[39m \u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecodermaxblock\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    250\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mIndexError\u001b[39;00m, struct\u001b[38;5;241m.\u001b[39merror) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    251\u001b[0m         \u001b[38;5;66;03m# truncated png/gif\u001b[39;00m\n\u001b[1;32m    252\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m LOAD_TRUNCATED_IMAGES:\n",
      "File \u001b[0;32m~/miniconda3/envs/histosslscaling/lib/python3.8/site-packages/PIL/PngImagePlugin.py:952\u001b[0m, in \u001b[0;36mPngImageFile.load_read\u001b[0;34m(self, read_bytes)\u001b[0m\n\u001b[1;32m    948\u001b[0m     read_bytes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(read_bytes, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__idat)\n\u001b[1;32m    950\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__idat \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__idat \u001b[38;5;241m-\u001b[39m read_bytes\n\u001b[0;32m--> 952\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mread_bytes\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_names = [ 'abmil',  'transmil']\n",
    "\n",
    "models={}\n",
    "for model_name in model_names:\n",
    "    # print(model_name)\n",
    "    model = get_model(model_name, input_dim, out_dim).to(device)\n",
    "    trainer = TorchTrainer(model, criterion, merics, device=device, num_epochs=cfg['epoch'], batch_size=cfg['bs'])\n",
    "    res = trainer.train(train_set, train_set)\n",
    "    # res = trainer.train(fake, fake)\n",
    "    models[model_name] = model\n",
    "\n",
    "\n",
    "    pha = 'train'\n",
    "    labels = np.array(res[pha][0])\n",
    "    probs = np.array(res[pha][1])\n",
    "    preds = np.array(res[pha][2])\n",
    "\n",
    "    type_labels = labels[0]\n",
    "    type_probs = probs[0]\n",
    "    type_preds = preds[0]\n",
    "\n",
    "    nonibc_index = np.where(type_labels ==1)\n",
    "    nonibc_labels = labels[1][nonibc_index]\n",
    "    nonibc_probs = probs[1][nonibc_index]\n",
    "    nonibc_preds = preds[1][nonibc_index]\n",
    "\n",
    "    ibc_index = np.where(type_labels ==2)\n",
    "    ibc_labels = labels[1][ibc_index]\n",
    "    ibc_probs = probs[1][ibc_index]\n",
    "    ibc_preds = preds[1][ibc_index]\n",
    "\n",
    "    re = {}\n",
    "    avg_aucs = {}\n",
    "    re['type'] = report(type_labels, type_preds, type_probs, class_names['type'])\n",
    "    avg_aucs['type'] = compute_mean_one_vs_all_auc(type_labels, type_probs)\n",
    "\n",
    "    re['nonibc'] = report(nonibc_labels, nonibc_preds, nonibc_probs, class_names['nonibc'])\n",
    "    avg_aucs['nonibc'] = compute_mean_one_vs_all_auc(nonibc_labels, nonibc_probs)\n",
    "\n",
    "    re['ibc'] = report(ibc_labels, ibc_preds, ibc_probs, class_names['ibc'])\n",
    "    avg_aucs['ibc'] = compute_mean_one_vs_all_auc(ibc_labels, ibc_probs)\n",
    "\n",
    "    for task in ['type', 'nonibc', 'ibc']:\n",
    "        r = re[task]\n",
    "        fs = \"{} {} {} acc: {:.4f}, auc: {:.4f} [{:.4f} {:.4f} {:.4f}]\".format(model_name, pha, task, r['accuracy'], avg_aucs[task], r['0']['auc'], r['1']['auc'], r['2']['auc'])\n",
    "        print(fs)\n",
    "    print()\n",
    "print()\n",
    "    \n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = [ 'abmil']\n",
    "models={}\n",
    "model_dir = Path('/mnt/hd0/project/bcacad/model/roi_models/model6')\n",
    "for model_name in model_names:\n",
    "    model = get_model(model_name, input_dim, out_dim).to(device)\n",
    "    model.load_state_dict(torch.load(model_dir / f'{model_name}.pth'))\n",
    "    models[model_name] = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shsu abmil type acc: 0.9469, auc: 0.9829 [nan 0.9836 0.9822]\n",
      "shsu abmil nonibc acc: 0.6189, auc: 0.7799 [0.8560 0.6719 0.8095]\n",
      "shsu abmil ibc acc: 0.6909, auc: 0.8562 [0.9802 0.7525 0.8352]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# testing\n",
    "pha='test'\n",
    "# test_cohorts = ['suqh_all_patch', 'qduh', 'shsu', 'bracs', 'bcnb', 'bach', 'apght']\n",
    "test_cohorts = [ 'shsu']\n",
    "# load_dir = Path('/mnt/hd0/project/bcacad/model/roi_models/model2')\n",
    "for cohort in test_cohorts:\n",
    "    for model_name in model_names:\n",
    "        # model = get_model(model_name, input_dim, out_dim).to(device)\n",
    "        model = models[model_name]\n",
    "        # ckpt = torch.load(load_dir / f'{model_name}.pth')\n",
    "        # model.load_state_dict(ckpt)\n",
    "        # model = model.to(device)\n",
    "\n",
    "        test_set = Feature(feature_root / cohort / 'test', 'test')\n",
    "        trainer = TorchTrainer(model, criterion, merics, device=device, num_epochs=50)\n",
    "        res = trainer.predict(test_set)\n",
    "\n",
    "        labels = np.array(res[0])\n",
    "        probs = np.array(res[1])\n",
    "        preds = np.array(res[2])\n",
    "\n",
    "        type_labels = labels[0]\n",
    "        type_probs = probs[0]\n",
    "        type_preds = preds[0]\n",
    "\n",
    "        nonibc_index = np.where(type_labels ==1)\n",
    "        nonibc_labels = labels[1][nonibc_index]\n",
    "        nonibc_probs = probs[1][nonibc_index]\n",
    "        nonibc_preds = preds[1][nonibc_index]\n",
    "\n",
    "        ibc_index = np.where(type_labels ==2)\n",
    "        ibc_labels = labels[1][ibc_index]\n",
    "        ibc_probs = probs[1][ibc_index]\n",
    "        ibc_preds = preds[1][ibc_index]\n",
    "\n",
    "        re = {}\n",
    "        avg_aucs = {}\n",
    "        if type_labels.size == 0:\n",
    "            re['type'] = None\n",
    "            avg_aucs['type'] = None\n",
    "        else:\n",
    "            re['type'] = report(type_labels, type_preds, type_probs, class_names['type'])\n",
    "            avg_aucs['type'] = compute_mean_one_vs_all_auc(type_labels, type_probs)\n",
    "\n",
    "        if nonibc_labels.size == 0:\n",
    "            re['nonibc'] = None\n",
    "            avg_aucs['nonibc'] = None\n",
    "        else:\n",
    "            re['nonibc'] = report(nonibc_labels, nonibc_preds, nonibc_probs, class_names['nonibc'])\n",
    "            avg_aucs['nonibc'] = compute_mean_one_vs_all_auc(nonibc_labels, nonibc_probs)\n",
    "\n",
    "        if ibc_labels.size == 0:\n",
    "            re['ibc'] = None\n",
    "            avg_aucs['ibc'] = None\n",
    "        else:\n",
    "            re['ibc'] = report(ibc_labels, ibc_preds, ibc_probs, class_names['ibc'])\n",
    "            avg_aucs['ibc'] = compute_mean_one_vs_all_auc(ibc_labels, ibc_probs)\n",
    "\n",
    "        for task in ['type', 'nonibc', 'ibc']:\n",
    "            r = re[task]\n",
    "            if r is None:\n",
    "                continue\n",
    "            fs = \"{} {} {} acc: {:.4f}, auc: {:.4f} [{:.4f} {:.4f} {:.4f}]\".format(cohort, model_name, task, r['accuracy'], avg_aucs[task], r['0']['auc'], r['1']['auc'], r['2']['auc'])\n",
    "            print(fs)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save abmil.pth\n",
      "save transmil.pth\n"
     ]
    }
   ],
   "source": [
    "save_root = Path('/mnt/hd0/project/bcacad/model/roi_models/model7')\n",
    "if not save_root.exists():\n",
    "    save_root.mkdir()\n",
    "for model_name in model_names:\n",
    "    torch.save(models[model_name].state_dict(), save_root / f'{model_name}.pth')\n",
    "    print(f'save {model_name}.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "histosslscaling",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
