{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from rl_benchmarks.models import iBOTViT\n",
    "from openslide import open_slide\n",
    "from openslide.deepzoom import DeepZoomGenerator\n",
    "import pathlib\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "Image.MAX_IMAGE_PIXELS = None\n",
    "from torchvision import transforms\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import os\n",
    "from multiprocessing import Pool\n",
    "import umap\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from rl_benchmarks.utils.linear_evaluation import get_binary_class_metrics, get_bootstrapped_metrics\n",
    "\n",
    "from PIL import Image\n",
    "import pathlib\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "Image.MAX_IMAGE_PIXELS = None\n",
    "from torchvision import transforms\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import os\n",
    "from multiprocessing import Pool\n",
    "# import umap\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision import transforms\n",
    "\n",
    "from sklearn.metrics import f1_score, precision_recall_fscore_support, roc_auc_score, confusion_matrix, cohen_kappa_score, accuracy_score\n",
    "import torch.nn.functional as F\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "# import albumentations as A\n",
    "# from albumentations.pytorch import ToTensorV2\n",
    "import cv2\n",
    "import time\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "import timm\n",
    "from metrics import report\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader, Subset, Dataset\n",
    "from tqdm import tqdm\n",
    "from rl_benchmarks.metrics import *\n",
    "\n",
    "from rl_benchmarks.trainers.torch_trainer import TorchTrainer\n",
    "from rl_benchmarks.models.slide_models.meanpool import MeanPool\n",
    "from rl_benchmarks.models.slide_models.chowder import Chowder\n",
    "from rl_benchmarks.models.slide_models.dsmil import DSMIL\n",
    "from rl_benchmarks.models.slide_models.abmil import ABMIL\n",
    "from rl_benchmarks.models.slide_models.hiptmil import HIPTMIL\n",
    "from rl_benchmarks.models.slide_models.transmil import TransMIL\n",
    "\n",
    "from pathlib import Path\n",
    "from metrics import report\n",
    "\n",
    "import sys\n",
    "sys.path.append('/home/yuxin/bme/BCaCAD/model')\n",
    "from patch_based_test.img import QiLuROI\n",
    "\n",
    "def get_model(model_name, in_dim, out_dim):\n",
    "    if model_name == 'abmil':\n",
    "        model = ABMIL(in_dim, out_dim, d_model_attention=128,temperature= 1.0, mlp_hidden= [128, 64])\n",
    "    elif model_name == 'chowder':\n",
    "        model = Chowder(in_dim, out_dim, n_top= 2,n_bottom= 2,tiles_mlp_hidden= [128], mlp_hidden= [128, 64])\n",
    "    elif model_name == 'dsmil':\n",
    "        model = DSMIL(in_dim, out_dim, d_tiles_values= 32,d_tiles_queries= 32,passing_values= False,tiles_scores_mlp_hidden=[200,100],\n",
    "                        tiles_queries_mlp_hidden=[200,100], mlp_hidden=[200,100])\n",
    "    elif model_name == 'hiptmil':\n",
    "        model = HIPTMIL(in_dim, out_dim)\n",
    "    elif model_name == 'transmil':\n",
    "        model = TransMIL(in_dim, out_features=out_dim)\n",
    "    elif model_name == 'meanpool':\n",
    "        model = MeanPool(in_dim, out_dim)\n",
    "    else:\n",
    "        raise 'model not found'\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IBOTMultiTaskModel(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(IBOTMultiTaskModel, self).__init__()\n",
    "        weights_path = '/home/yuxin/Downloads/ibot_vit_base_pancan.pth'\n",
    "        self.base_model = iBOTViT(architecture=\"vit_base_pancan\", encoder=\"teacher\", weights_path=weights_path)\n",
    "        # print(self.base_model)\n",
    "        self.num_features = 768\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        if isinstance(num_classes, list):\n",
    "            self.heads = nn.ModuleList([nn.Linear(self.num_features, num_class) for num_class in num_classes])\n",
    "        else:\n",
    "            self.head = self.base_model.head\n",
    "            self.head.fc = nn.Linear(self.num_features, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Forward pass through the base model\n",
    "        x = self.base_model(x)\n",
    "        if isinstance(self.num_classes, list):\n",
    "            x = [head(x) for head in self.heads]\n",
    "        else:\n",
    "            x = self.head(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "num_classes = [3,3]\n",
    "img_size = patch_size = 384\n",
    "data_trans = {\n",
    "    \"train\": transforms.Compose([\n",
    "                                transforms.Resize(img_size),\n",
    "                                transforms.ColorJitter(),\n",
    "                                transforms.RandomHorizontalFlip(),\n",
    "                                transforms.RandomVerticalFlip(),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])]),\n",
    "    \"test\": transforms.Compose([\n",
    "                                transforms.Resize((img_size,img_size)),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-07-10 20:02:37.079\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrl_benchmarks.models.feature_extractors.ibot_vit\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m78\u001b[0m - \u001b[1mPretrained weights found at /home/yuxin/Downloads/ibot_vit_base_pancan.pth and loaded with msg: _IncompatibleKeys(missing_keys=[], unexpected_keys=['head.mlp.0.weight', 'head.mlp.0.bias', 'head.mlp.2.weight', 'head.mlp.2.bias', 'head.mlp.4.weight', 'head.mlp.4.bias', 'head.last_layer.weight_g', 'head.last_layer.weight_v', 'head.last_layer2.weight_g', 'head.last_layer2.weight_v'])\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_model = IBOTMultiTaskModel(num_classes)\n",
    "device = \"cuda\"\n",
    "feature_model.to(device)\n",
    "feature_model = nn.DataParallel(feature_model)\n",
    "weight_path = '/mnt/hd0/project/bcacad/model/pretrainSSL_ibot_vit+ibot_ft+fsl_ft/model-5.pth'\n",
    "feature_model.load_state_dict(torch.load(weight_path, map_location=device)['model_state_dict'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Feature_Fly(Dataset):\n",
    "    def get_label(self, type):\n",
    "        D = {\n",
    "            'normal':[0,0],\n",
    "            'dcis-1':[1,0],\n",
    "            'dcis-2':[1,1],\n",
    "            'dcis-3':[1,2],\n",
    "            'ibc-1':[2,0],\n",
    "            'ibc-2':[2,1],\n",
    "            'ibc-3':[2,2],\n",
    "        }\n",
    "        label =  D[type]\n",
    "        return label[0],label[1]\n",
    "    \n",
    "    def __init__(self, image_dir, phase='test', train_tile=None):\n",
    "        folder = Path(image_dir)\n",
    "        self.im_paths = list(folder.rglob('**/*.*'))\n",
    "        self.labels = [self.get_label(path.parent.name) for path in self.im_paths]\n",
    "        self.phase=phase\n",
    "        self.train_tile = train_tile\n",
    "        self.size = 336\n",
    "        self.bs = 16\n",
    "        self.src_mag = 10\n",
    "        self.tar_mag = 10\n",
    "    \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.im_paths)\n",
    "    def __getitem__(self, item):\n",
    "        im_path = self.im_paths[item]\n",
    "        im = QiLuROI(str(im_path), self.src_mag, self.tar_mag, self.size)\n",
    "        im.setIterator(self.size)\n",
    "        patches = [p for p in im]\n",
    "        if self.phase == 'train':\n",
    "            indices = np.random.choice(len(patches), self.train_tile, replace=True)\n",
    "            patches = [patches[i] for i in indices]\n",
    "        patches = [data_trans[self.phase](p) for p in patches]\n",
    "        bs = self.bs\n",
    "        for i in range(0, len(patches), bs):\n",
    "            x = torch.stack(patches[i:i+bs], dim=0)\n",
    "            x = x.to(device)\n",
    "            y = feature_model.module.base_model(x)\n",
    "            if i == 0:\n",
    "                features = y#.detach().cpu().numpy()\n",
    "            else:\n",
    "                features = torch.concatenate([features, y], dim=0)\n",
    "                #np.concatenate([features, y.detach().cpu().numpy()], axis=0)\n",
    "        return features, self.labels[item]\n",
    "    \n",
    "    @staticmethod\n",
    "    def collate_fn(batch):\n",
    "        # 官方实现的default_collate可以参考\n",
    "        # https://github.com/pytorch/pytorch/blob/67b7e751e6b5931a9f45274653f4f653a4e6cdf6/torch/utils/data/_utils/collate.py\n",
    "        images,  labels = tuple(zip(*batch))\n",
    "\n",
    "        images = torch.stack(images, dim=0)\n",
    "        labels = torch.as_tensor(labels)\n",
    "        # masks = torch.as_tensor(masks)\n",
    "\n",
    "        return images, labels\n",
    "\n",
    "class Feature(Dataset):\n",
    "    def get_label(self, type):\n",
    "        D = {\n",
    "            'normal':[0,0],\n",
    "            'dcis-1':[1,0],\n",
    "            'dcis-2':[1,1],\n",
    "            'dcis-3':[1,2],\n",
    "            'ibc-1':[2,0],\n",
    "            'ibc-2':[2,1],\n",
    "            'ibc-3':[2,2],\n",
    "        }\n",
    "        label =  D[type]\n",
    "        return label[0],label[1]\n",
    "    \n",
    "    def __init__(self, feature_dir, phase='test'):\n",
    "        folder = Path(feature_dir)\n",
    "        feature_paths = list(folder.rglob('**/*.npy'))\n",
    "        self.names = [path.stem for path in feature_paths]\n",
    "        # self.labels = [self.get_label(path.parent.name) for path in feature_paths]\n",
    "        self.features = [np.load(path) for path in feature_paths]\n",
    "        self.phase=phase\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "    def __getitem__(self, item):\n",
    "        features = self.features[item]\n",
    "        if self.phase == 'train':\n",
    "            indices = np.random.choice(features.shape[0], 8, replace=True)\n",
    "            features = np.stack([features[i] for i in indices], axis=0)\n",
    "        return features, [0,0]\n",
    "    \n",
    "    @staticmethod\n",
    "    def collate_fn(batch):\n",
    "        # 官方实现的default_collate可以参考\n",
    "        # https://github.com/pytorch/pytorch/blob/67b7e751e6b5931a9f45274653f4f653a4e6cdf6/torch/utils/data/_utils/collate.py\n",
    "        images,  labels = tuple(zip(*batch))\n",
    "\n",
    "        images = torch.stack(images, dim=0)\n",
    "        labels = torch.as_tensor(labels)\n",
    "        # masks = torch.as_tensor(masks)\n",
    "\n",
    "        return images, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = dict(\n",
    "    epoch=2,\n",
    "    bs=8,\n",
    "    train_tiles = 4,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root = Path('/mnt/hd0/project/bcacad/data/roi-level')\n",
    "feature_root = Path('/mnt/hd0/project/bcacad/model/roi_features')\n",
    "test_cohorts = ['suqh_all_patch', 'qduh', 'shsu', 'bracs', 'bcnb', 'bach', 'apght']\n",
    "# test_cohorts = ['suqh_all_patch']\n",
    "train_set = Feature_Fly(data_root / 'suqh' / 'model', 'train', cfg['train_tiles'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 768])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "merics = {'acc': compute_multiclass_accuracy, 'auc': compute_mean_one_vs_all_auc}\n",
    "input_dim = 768\n",
    "out_dim = [3,3]\n",
    "tasks = ['type', 'nonibc', 'ibc']\n",
    "class_names = {\n",
    "    'type': ['Normal', 'nonIBC', 'IBC'],\n",
    "    'nonibc': ['Low', 'Medium', 'High'],\n",
    "    'ibc': ['Low', 'Medium', 'High'],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_names = [ 'abmil',  'transmil']\n",
    "\n",
    "# models={}\n",
    "# for model_name in model_names:\n",
    "#     # print(model_name)\n",
    "#     model = get_model(model_name, input_dim, out_dim).to(device)\n",
    "#     trainer = TorchTrainer(model, criterion, merics, device=device, num_epochs=cfg['epoch'], batch_size=cfg['bs'])\n",
    "#     res = trainer.train(train_set, train_set)\n",
    "#     # res = trainer.train(fake, fake)\n",
    "#     models[model_name] = model\n",
    "\n",
    "\n",
    "#     pha = 'train'\n",
    "#     labels = np.array(res[pha][0])\n",
    "#     probs = np.array(res[pha][1])\n",
    "#     preds = np.array(res[pha][2])\n",
    "\n",
    "#     type_labels = labels[0]\n",
    "#     type_probs = probs[0]\n",
    "#     type_preds = preds[0]\n",
    "\n",
    "#     nonibc_index = np.where(type_labels ==1)\n",
    "#     nonibc_labels = labels[1][nonibc_index]\n",
    "#     nonibc_probs = probs[1][nonibc_index]\n",
    "#     nonibc_preds = preds[1][nonibc_index]\n",
    "\n",
    "#     ibc_index = np.where(type_labels ==2)\n",
    "#     ibc_labels = labels[1][ibc_index]\n",
    "#     ibc_probs = probs[1][ibc_index]\n",
    "#     ibc_preds = preds[1][ibc_index]\n",
    "\n",
    "#     re = {}\n",
    "#     avg_aucs = {}\n",
    "#     re['type'] = report(type_labels, type_preds, type_probs, class_names['type'])\n",
    "#     avg_aucs['type'] = compute_mean_one_vs_all_auc(type_labels, type_probs)\n",
    "\n",
    "#     re['nonibc'] = report(nonibc_labels, nonibc_preds, nonibc_probs, class_names['nonibc'])\n",
    "#     avg_aucs['nonibc'] = compute_mean_one_vs_all_auc(nonibc_labels, nonibc_probs)\n",
    "\n",
    "#     re['ibc'] = report(ibc_labels, ibc_preds, ibc_probs, class_names['ibc'])\n",
    "#     avg_aucs['ibc'] = compute_mean_one_vs_all_auc(ibc_labels, ibc_probs)\n",
    "\n",
    "#     for task in ['type', 'nonibc', 'ibc']:\n",
    "#         r = re[task]\n",
    "#         fs = \"{} {} {} acc: {:.4f}, auc: {:.4f} [{:.4f} {:.4f} {:.4f}]\".format(model_name, pha, task, r['accuracy'], avg_aucs[task], r['0']['auc'], r['1']['auc'], r['2']['auc'])\n",
    "#         print(fs)\n",
    "#     print()\n",
    "# print()\n",
    "    \n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = [ 'abmil']\n",
    "models={}\n",
    "model_dir = Path('/mnt/hd0/project/bcacad/model/roi_models/model6')\n",
    "for model_name in model_names:\n",
    "    model = get_model(model_name, input_dim, out_dim).to(device)\n",
    "    model.load_state_dict(torch.load(model_dir / f'{model_name}.pth'))\n",
    "    models[model_name] = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing\n",
    "pha='test'\n",
    "# test_cohorts = ['suqh_all_patch', 'qduh', 'shsu', 'bracs', 'bcnb', 'bach', 'apght']\n",
    "test_cohorts = [Path('/mnt/hd0/project/bcacad/model/100_rois')]\n",
    "# load_dir = Path('/mnt/hd0/project/bcacad/model/roi_models/model2')\n",
    "for cohort in test_cohorts:\n",
    "    for model_name in model_names:\n",
    "        # model = get_model(model_name, input_dim, out_dim).to(device)\n",
    "        model = models[model_name]\n",
    "        # ckpt = torch.load(load_dir / f'{model_name}.pth')\n",
    "        # model.load_state_dict(ckpt)\n",
    "        # model = model.to(device)\n",
    "\n",
    "        test_set = Feature(cohort, 'test')\n",
    "        trainer = TorchTrainer(model, criterion, merics, device=device, num_epochs=50)\n",
    "        res = trainer.predict(test_set)\n",
    "\n",
    "        probs = np.array(res[1])\n",
    "        preds = np.array(res[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_preds = preds[0]\n",
    "grade_preds = preds[1]\n",
    "type_probs = probs[0]\n",
    "grade_probs = probs[1]\n",
    "names = test_set.names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def remove_pattern_and_extract(input_string):\n",
    "    pattern = r'(-10x.*)'\n",
    "    match = re.search(pattern, input_string)\n",
    "    if match:\n",
    "        result = input_string[:match.start()]\n",
    "        return result\n",
    "    else:\n",
    "        return input_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = [remove_pattern_and_extract(name) for name in names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "type_data = {\n",
    "    'name': names,\n",
    "    'pred' : type_preds,\n",
    "    'prob-0' : type_probs[:,0],\n",
    "    'prob-1' : type_probs[:,1],\n",
    "    'prob-2' : type_probs[:,2],\n",
    "}\n",
    "df = pd.DataFrame(type_data)\n",
    "df.to_excel('100_roi_type_preds_v2.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "grade_data = {\n",
    "    'name': names,\n",
    "    'pred' : type_preds,\n",
    "    'prob-0' : grade_probs[:,0],\n",
    "    'prob-1' : grade_probs[:,1],\n",
    "    'prob-2' : grade_probs[:,2],\n",
    "}\n",
    "df = pd.DataFrame(grade_data)\n",
    "df.to_excel('100_roi_grade_preds_v2.xlsx', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "histosslscaling",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
