{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader, Subset, Dataset\n",
    "from tqdm import tqdm\n",
    "from rl_benchmarks.metrics import *\n",
    "\n",
    "from rl_benchmarks.trainers.torch_trainer import TorchTrainer\n",
    "from rl_benchmarks.models.slide_models.meanpool import MeanPool\n",
    "from rl_benchmarks.models.slide_models.chowder import Chowder\n",
    "from rl_benchmarks.models.slide_models.dsmil import DSMIL\n",
    "from rl_benchmarks.models.slide_models.abmil import ABMIL\n",
    "from rl_benchmarks.models.slide_models.hiptmil import HIPTMIL\n",
    "from rl_benchmarks.models.slide_models.transmil import TransMIL\n",
    "\n",
    "from pathlib import Path\n",
    "from metrics import report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(model_name, in_dim, out_dim):\n",
    "    if model_name == 'abmil':\n",
    "        model = ABMIL(in_dim, out_dim, d_model_attention=128,temperature= 1.0, mlp_hidden= [128, 64])\n",
    "    elif model_name == 'chowder':\n",
    "        model = Chowder(in_dim, out_dim, n_top= 2,n_bottom= 2,tiles_mlp_hidden= [128], mlp_hidden= [128, 64])\n",
    "    elif model_name == 'dsmil':\n",
    "        model = DSMIL(in_dim, out_dim, d_tiles_values= 32,d_tiles_queries= 32,passing_values= False,tiles_scores_mlp_hidden=[200,100],\n",
    "                        tiles_queries_mlp_hidden=[200,100], mlp_hidden=[200,100])\n",
    "    elif model_name == 'hiptmil':\n",
    "        model = HIPTMIL(in_dim, out_dim)\n",
    "    elif model_name == 'transmil':\n",
    "        model = TransMIL(in_dim, out_features=out_dim)\n",
    "    elif model_name == 'meanpool':\n",
    "        model = MeanPool(in_dim, out_dim)\n",
    "    else:\n",
    "        raise 'model not found'\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FakeDataset(Dataset):\n",
    "    \"\"\"自定义数据集\"\"\"\n",
    "\n",
    "    # def __init__(self, images_path: list, images_class: list, images_ncl: list, images_epi: list, images_tub: list, images_mit: list, transform=None):\n",
    "    def __init__(self):\n",
    "      pass\n",
    "\n",
    "    def __len__(self):\n",
    "        return 185\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        n_tiles = torch.randint(20, [1]).item()\n",
    "        feature = torch.rand(n_tiles, 768)\n",
    "        label = [torch.randint(3,[1]).item(), torch.randint(3,[1]).item()]\n",
    "        return feature, label\n",
    "\n",
    "    @staticmethod\n",
    "    def collate_fn(batch):\n",
    "        # 官方实现的default_collate可以参考\n",
    "        # https://github.com/pytorch/pytorch/blob/67b7e751e6b5931a9f45274653f4f653a4e6cdf6/torch/utils/data/_utils/collate.py\n",
    "        images,  labels = tuple(zip(*batch))\n",
    "\n",
    "        images = torch.stack(images, dim=0)\n",
    "        labels = torch.as_tensor(labels)\n",
    "        # masks = torch.as_tensor(masks)\n",
    "\n",
    "        return images, labels\n",
    "\n",
    "class Feature(FakeDataset):\n",
    "    def get_label(self, type):\n",
    "        D = {\n",
    "            'normal':[0,0],\n",
    "            'dcis-1':[1,0],\n",
    "            'dcis-2':[1,1],\n",
    "            'dcis-3':[1,2],\n",
    "            'ibc-1':[2,0],\n",
    "            'ibc-2':[2,1],\n",
    "            'ibc-3':[2,2],\n",
    "        }\n",
    "        label =  D[type]\n",
    "        return label[0],label[1]\n",
    "    \n",
    "    def __init__(self, feature_dir, phase='test'):\n",
    "        folder = Path(feature_dir)\n",
    "        feature_paths = list(folder.rglob('**/*.npy'))\n",
    "        self.labels = [self.get_label(path.parent.name) for path in feature_paths]\n",
    "        self.features = [np.load(path) for path in feature_paths]\n",
    "        self.phase=phase\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "    def __getitem__(self, item):\n",
    "        features = self.features[item]\n",
    "        if self.phase == 'train':\n",
    "            indices = np.random.choice(features.shape[0], 8, replace=True)\n",
    "            features = np.stack([features[i] for i in indices], axis=0)\n",
    "        return features, self.labels[item]\n",
    "    \n",
    "    @staticmethod\n",
    "    def collate_fn(batch):\n",
    "        # 官方实现的default_collate可以参考\n",
    "        # https://github.com/pytorch/pytorch/blob/67b7e751e6b5931a9f45274653f4f653a4e6cdf6/torch/utils/data/_utils/collate.py\n",
    "        images,  labels = tuple(zip(*batch))\n",
    "\n",
    "        images = torch.stack(images, dim=0)\n",
    "        labels = torch.as_tensor(labels)\n",
    "        # masks = torch.as_tensor(masks)\n",
    "\n",
    "        return images, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "merics = {'acc': compute_multiclass_accuracy, 'auc': compute_mean_one_vs_all_auc}\n",
    "# train_dir = '/mnt/hd0/project/bcacad/model/roi_features/suqh/model'\n",
    "# test_dir = '/mnt/hd0/project/bcacad/model/roi_features/suqh/test'\n",
    "# train_dir = '/mnt/hd0/project/bcacad/model/roi_features/suqh_full/model'\n",
    "# test_dir = '/mnt/hd0/project/bcacad/model/roi_features/suqh_full/test'\n",
    "train_dir = '/mnt/hd0/project/bcacad/model/roi_features/suqh_all_patch_balance/model'\n",
    "test_dir = '/mnt/hd0/project/bcacad/model/roi_features/suqh_all_patch/test'\n",
    "train_set = Feature(train_dir, 'train')\n",
    "test_set = Feature(test_dir, 'test')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake = FakeDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_names = ['meanpool', 'abmil', 'chowder', 'dsmil', 'hiptmil', 'transmil']\n",
    "# model_names = ['meanpool', 'abmil', 'chowder', 'transmil']\n",
    "model_names = [ 'abmil',  'transmil']\n",
    "# model_names = ['transmil']\n",
    "input_dim = 768\n",
    "out_dim = [3,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [18:50<00:00,  5.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abmil train type acc: 0.9982, auc: 0.9999 [1.0000 0.9998 1.0000]\n",
      "abmil train nonibc acc: 0.9801, auc: 0.9971 [0.9993 0.9944 0.9975]\n",
      "abmil train ibc acc: 0.9908, auc: 0.9989 [0.9998 0.9985 0.9984]\n",
      "\n",
      "abmil test type acc: 0.8940, auc: 0.9851 [0.9940 0.9704 0.9912]\n",
      "abmil test nonibc acc: 0.5331, auc: 0.7283 [0.7565 0.6091 0.8212]\n",
      "abmil test ibc acc: 0.6682, auc: 0.7704 [0.8356 0.6768 0.8001]\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [1:14:10<00:00, 22.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transmil train type acc: 0.9984, auc: 0.9989 [1.0000 0.9980 0.9988]\n",
      "transmil train nonibc acc: 0.9740, auc: 0.9803 [0.9997 0.9467 0.9941]\n",
      "transmil train ibc acc: 0.9929, auc: 0.9904 [0.9996 0.9718 0.9997]\n",
      "\n",
      "transmil test type acc: 0.9396, auc: 0.9736 [0.9953 0.9608 0.9647]\n",
      "transmil test nonibc acc: 0.5784, auc: 0.7384 [0.7199 0.6538 0.8451]\n",
      "transmil test ibc acc: 0.6541, auc: 0.7672 [0.8685 0.6562 0.7783]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cfg = dict(\n",
    "    epoch=200,\n",
    "    bs=16\n",
    ")\n",
    "models={}\n",
    "for model_name in model_names:\n",
    "    # print(model_name)\n",
    "    model = get_model(model_name, input_dim, out_dim).to(device)\n",
    "    trainer = TorchTrainer(model, criterion, merics, device=device, num_epochs=cfg['epoch'], batch_size=cfg['bs'])\n",
    "    res = trainer.train(train_set, test_set)\n",
    "    # res = trainer.train(fake, fake)\n",
    "    models[model_name] = model\n",
    "    tasks = ['type', 'nonibc', 'ibc']\n",
    "    class_names = {\n",
    "        'type': ['Normal', 'nonIBC', 'IBC'],\n",
    "        'nonibc': ['Low', 'Medium', 'High'],\n",
    "        'ibc': ['Low', 'Medium', 'High'],\n",
    "    }\n",
    "\n",
    "    for pha in ['train', 'test']:\n",
    "        labels = np.array(res[pha][0])\n",
    "        probs = np.array(res[pha][1])\n",
    "        preds = np.array(res[pha][2])\n",
    "\n",
    "        type_labels = labels[0]\n",
    "        type_probs = probs[0]\n",
    "        type_preds = preds[0]\n",
    "\n",
    "        nonibc_index = np.where(type_labels ==1)\n",
    "        nonibc_labels = labels[1][nonibc_index]\n",
    "        nonibc_probs = probs[1][nonibc_index]\n",
    "        nonibc_preds = preds[1][nonibc_index]\n",
    "\n",
    "        ibc_index = np.where(type_labels ==2)\n",
    "        ibc_labels = labels[1][ibc_index]\n",
    "        ibc_probs = probs[1][ibc_index]\n",
    "        ibc_preds = preds[1][ibc_index]\n",
    "\n",
    "        re = {}\n",
    "        avg_aucs = {}\n",
    "        re['type'] = report(type_labels, type_preds, type_probs, class_names['type'])\n",
    "        avg_aucs['type'] = compute_mean_one_vs_all_auc(type_labels, type_probs)\n",
    "\n",
    "        re['nonibc'] = report(nonibc_labels, nonibc_preds, nonibc_probs, class_names['nonibc'])\n",
    "        avg_aucs['nonibc'] = compute_mean_one_vs_all_auc(nonibc_labels, nonibc_probs)\n",
    "\n",
    "        re['ibc'] = report(ibc_labels, ibc_preds, ibc_probs, class_names['ibc'])\n",
    "        avg_aucs['ibc'] = compute_mean_one_vs_all_auc(ibc_labels, ibc_probs)\n",
    "\n",
    "        for task in ['type', 'nonibc', 'ibc']:\n",
    "            r = re[task]\n",
    "            fs = \"{} {} {} acc: {:.4f}, auc: {:.4f} [{:.4f} {:.4f} {:.4f}]\".format(model_name, pha, task, r['accuracy'], avg_aucs[task], r['0']['auc'], r['1']['auc'], r['2']['auc'])\n",
    "            print(fs)\n",
    "        print()\n",
    "    print()\n",
    "    \n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'epoch': 100, 'bs': 16}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m save_dir \u001b[38;5;241m=\u001b[39m \u001b[43mPath\u001b[49m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/mnt/hd0/project/bcacad/model/roi_models/model2\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      2\u001b[0m save_dir\u001b[38;5;241m.\u001b[39mmkdir(exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, parents\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m model_name, model \u001b[38;5;129;01min\u001b[39;00m models\u001b[38;5;241m.\u001b[39mitems():\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Path' is not defined"
     ]
    }
   ],
   "source": [
    "save_dir = Path('/mnt/hd0/project/bcacad/model/roi_models/model2')\n",
    "save_dir.mkdir(exist_ok=True, parents=True)\n",
    "for model_name, model in models.items():\n",
    "    torch.save(model.state_dict(), save_dir / f'{model_name}.pth')\n",
    "    print(f'save {model_name} done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abmil test type acc: 0.9235, auc: 0.9916 [0.9932 0.9914 0.9902]\n",
      "abmil test nonibc acc: 0.5784, auc: 0.7118 [0.6742 0.6248 0.8400]\n",
      "abmil test ibc acc: 0.6729, auc: 0.7539 [0.8320 0.6772 0.7539]\n",
      "transmil test type acc: 0.9477, auc: 0.9813 [0.9922 0.9735 0.9781]\n",
      "transmil test nonibc acc: 0.5401, auc: 0.7023 [0.6550 0.6448 0.8105]\n",
      "transmil test ibc acc: 0.7058, auc: 0.7648 [0.8328 0.6676 0.7956]\n"
     ]
    }
   ],
   "source": [
    "pha='test'\n",
    "load_dir = Path('/mnt/hd0/project/bcacad/model/roi_models/model2')\n",
    "for model_name in model_names:\n",
    "    model = get_model(model_name, input_dim, out_dim).to(device)\n",
    "    ckpt = torch.load(load_dir / f'{model_name}.pth')\n",
    "    model.load_state_dict(ckpt)\n",
    "    model = model.to(device)\n",
    "\n",
    "\n",
    "    trainer = TorchTrainer(model, criterion, merics, device=device, num_epochs=50)\n",
    "    res = trainer.predict(test_set)\n",
    "    tasks = ['type', 'nonibc', 'ibc']\n",
    "    class_names = {\n",
    "        'type': ['Normal', 'nonIBC', 'IBC'],\n",
    "        'nonibc': ['Low', 'Medium', 'High'],\n",
    "        'ibc': ['Low', 'Medium', 'High'],\n",
    "    }\n",
    "\n",
    "\n",
    "    labels = np.array(res[0])\n",
    "    probs = np.array(res[1])\n",
    "    preds = np.array(res[2])\n",
    "\n",
    "    type_labels = labels[0]\n",
    "    type_probs = probs[0]\n",
    "    type_preds = preds[0]\n",
    "\n",
    "    nonibc_index = np.where(type_labels ==1)\n",
    "    nonibc_labels = labels[1][nonibc_index]\n",
    "    nonibc_probs = probs[1][nonibc_index]\n",
    "    nonibc_preds = preds[1][nonibc_index]\n",
    "\n",
    "    ibc_index = np.where(type_labels ==2)\n",
    "    ibc_labels = labels[1][ibc_index]\n",
    "    ibc_probs = probs[1][ibc_index]\n",
    "    ibc_preds = preds[1][ibc_index]\n",
    "\n",
    "    re = {}\n",
    "    avg_aucs = {}\n",
    "    re['type'] = report(type_labels, type_preds, type_probs, class_names['type'])\n",
    "    avg_aucs['type'] = compute_mean_one_vs_all_auc(type_labels, type_probs)\n",
    "\n",
    "    re['nonibc'] = report(nonibc_labels, nonibc_preds, nonibc_probs, class_names['nonibc'])\n",
    "    avg_aucs['nonibc'] = compute_mean_one_vs_all_auc(nonibc_labels, nonibc_probs)\n",
    "\n",
    "    re['ibc'] = report(ibc_labels, ibc_preds, ibc_probs, class_names['ibc'])\n",
    "    avg_aucs['ibc'] = compute_mean_one_vs_all_auc(ibc_labels, ibc_probs)\n",
    "\n",
    "    for task in ['type', 'nonibc', 'ibc']:\n",
    "        r = re[task]\n",
    "        fs = \"{} {} {} acc: {:.4f}, auc: {:.4f} [{:.4f} {:.4f} {:.4f}]\".format(model_name, pha, task, r['accuracy'], avg_aucs[task], r['0']['auc'], r['1']['auc'], r['2']['auc'])\n",
    "        print(fs)\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "histosslscaling",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
