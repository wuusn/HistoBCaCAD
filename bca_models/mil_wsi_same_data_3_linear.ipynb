{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from rl_benchmarks.models import iBOTViT\n",
    "from openslide import open_slide\n",
    "from openslide.deepzoom import DeepZoomGenerator\n",
    "import pathlib\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "Image.MAX_IMAGE_PIXELS = None\n",
    "from torchvision import transforms\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import os\n",
    "from multiprocessing import Pool\n",
    "import umap\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from rl_benchmarks.utils.linear_evaluation import get_binary_class_metrics, get_bootstrapped_metrics\n",
    "\n",
    "from PIL import Image\n",
    "import pathlib\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "Image.MAX_IMAGE_PIXELS = None\n",
    "from torchvision import transforms\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import os\n",
    "from multiprocessing import Pool\n",
    "# import umap\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision import transforms\n",
    "\n",
    "from sklearn.metrics import f1_score, precision_recall_fscore_support, roc_auc_score, confusion_matrix, cohen_kappa_score, accuracy_score\n",
    "import torch.nn.functional as F\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "# import albumentations as A\n",
    "# from albumentations.pytorch import ToTensorV2\n",
    "import cv2\n",
    "import time\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "import timm\n",
    "from metrics import report\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader, Subset, Dataset\n",
    "from tqdm import tqdm\n",
    "from rl_benchmarks.metrics import *\n",
    "\n",
    "from rl_benchmarks.trainers.torch_trainer import TorchTrainer\n",
    "from rl_benchmarks.models.slide_models.meanpool import MeanPool\n",
    "from rl_benchmarks.models.slide_models.chowder import Chowder\n",
    "from rl_benchmarks.models.slide_models.dsmil import DSMIL\n",
    "from rl_benchmarks.models.slide_models.abmil import ABMIL\n",
    "from rl_benchmarks.models.slide_models.hiptmil import HIPTMIL\n",
    "from rl_benchmarks.models.slide_models.transmil import TransMIL\n",
    "\n",
    "from pathlib import Path\n",
    "from metrics import report\n",
    "\n",
    "import sys\n",
    "sys.path.append('/home/yuxin/bme/BCaCAD/model')\n",
    "from patch_based_test.img import QiLuROI\n",
    "\n",
    "def get_model(model_name, in_dim, out_dim):\n",
    "    if model_name == 'abmil':\n",
    "        model = ABMIL(in_dim, out_dim, d_model_attention=128,temperature= 1.0, mlp_hidden= [128, 64])\n",
    "    elif model_name == 'chowder':\n",
    "        model = Chowder(in_dim, out_dim, n_top= 2,n_bottom= 2,tiles_mlp_hidden= [128], mlp_hidden= [128, 64])\n",
    "    elif model_name == 'dsmil':\n",
    "        model = DSMIL(in_dim, out_dim, d_tiles_values= 32,d_tiles_queries= 32,passing_values= False,tiles_scores_mlp_hidden=[200,100],\n",
    "                        tiles_queries_mlp_hidden=[200,100], mlp_hidden=[200,100])\n",
    "    elif model_name == 'hiptmil':\n",
    "        model = HIPTMIL(in_dim, out_dim)\n",
    "    elif model_name == 'transmil':\n",
    "        model = TransMIL(in_dim, out_features=out_dim)\n",
    "    elif model_name == 'meanpool':\n",
    "        model = MeanPool(in_dim, out_dim)\n",
    "    else:\n",
    "        raise 'model not found'\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "num_classes = [3,3]\n",
    "img_size = patch_size = 384\n",
    "data_trans = {\n",
    "    \"train\": transforms.Compose([\n",
    "                                transforms.Resize(img_size),\n",
    "                                transforms.ColorJitter(),\n",
    "                                transforms.RandomHorizontalFlip(),\n",
    "                                transforms.RandomVerticalFlip(),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])]),\n",
    "    \"test\": transforms.Compose([\n",
    "                                transforms.Resize((img_size,img_size)),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Feature(Dataset):\n",
    "    def get_label(self, type):\n",
    "        D = {\n",
    "            'normal':[0,0],\n",
    "            'dcis-1':[1,0],\n",
    "            'dcis-2':[1,1],\n",
    "            'dcis-3':[1,2],\n",
    "            'ibc-1':[2,0],\n",
    "            'ibc-2':[2,1],\n",
    "            'ibc-3':[2,2],\n",
    "        }\n",
    "        label =  D[type]\n",
    "        return label[0],label[1]\n",
    "    \n",
    "    def __init__(self, feature_dir, phase='test'):\n",
    "        folder = Path(feature_dir)\n",
    "        feature_paths = list(folder.rglob('**/*.npy'))\n",
    "        self.labels = [self.get_label(path.parent.parent.name) for path in feature_paths]\n",
    "        self.features = [np.load(path) for path in feature_paths]\n",
    "        self.phase=phase\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "    def __getitem__(self, item):\n",
    "        features = self.features[item]\n",
    "        if self.phase == 'train':\n",
    "            indices = np.random.choice(features.shape[0], 8, replace=True)\n",
    "            features = np.stack([features[i] for i in indices], axis=0)\n",
    "        return features, self.labels[item]\n",
    "    \n",
    "    @staticmethod\n",
    "    def collate_fn(batch):\n",
    "        # 官方实现的default_collate可以参考\n",
    "        # https://github.com/pytorch/pytorch/blob/67b7e751e6b5931a9f45274653f4f653a4e6cdf6/torch/utils/data/_utils/collate.py\n",
    "        images,  labels = tuple(zip(*batch))\n",
    "\n",
    "        images = torch.stack(images, dim=0)\n",
    "        labels = torch.as_tensor(labels)\n",
    "        # masks = torch.as_tensor(masks)\n",
    "\n",
    "        return images, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_root = Path('/mnt/hd0/project/bcacad/data/roi-level')\n",
    "feature_root = Path('/mnt/hd0/project/bcacad/model/wsi_features')\n",
    "test_cohorts = ['suqh_all_patch', 'qduh', 'shsu', 'bracs', 'bcnb', 'bach', 'apght']\n",
    "# test_cohorts = ['suqh_all_patch']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "merics = {'acc': compute_multiclass_accuracy, 'auc': compute_mean_one_vs_all_auc}\n",
    "input_dim = 768\n",
    "out_dim = [3,3]\n",
    "tasks = ['type', 'nonibc', 'ibc']\n",
    "class_names = {\n",
    "    'type': ['Normal', 'nonIBC', 'IBC'],\n",
    "    'nonibc': ['Low', 'Medium', 'High'],\n",
    "    'ibc': ['Low', 'Medium', 'High'],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = [ 'abmil']\n",
    "models={}\n",
    "model_dir = Path('/mnt/hd0/project/bcacad/model/roi_models/model6')\n",
    "for model_name in model_names:\n",
    "    model = get_model(model_name, input_dim, out_dim).to(device)\n",
    "    model.load_state_dict(torch.load(model_dir / f'{model_name}.pth'))\n",
    "    models[model_name] = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = Feature(feature_root / 'suqh' / 'model', 'train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "Y = []\n",
    "for i in range(len(train_set)):\n",
    "    x, y = train_set[i]\n",
    "    x = torch.Tensor(x).to(device)\n",
    "    x = x.unsqueeze(0)\n",
    "    # print(x.shape)\n",
    "    output = models['abmil'](x)\n",
    "    output = [output[0].cpu().detach().numpy(), output[1].cpu().detach().numpy()]\n",
    "    output = np.array(output).reshape(-1)\n",
    "    X.append(output)\n",
    "    Y.append(y)\n",
    "X = np.array(X)\n",
    "Y = np.array(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "import numpy as np\n",
    "\n",
    "clf = sklearn.linear_model.SGDClassifier(\n",
    "                loss=\"log_loss\",\n",
    "                penalty=\"l2\",\n",
    "                learning_rate=\"adaptive\",\n",
    "                eta0=1e-4,\n",
    "                n_jobs=8,\n",
    "                early_stopping=False,\n",
    "                random_state=2023,\n",
    "            )\n",
    "mclf = MultiOutputClassifier(clf, n_jobs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultiOutputClassifier(estimator=SGDClassifier(eta0=0.0001,\n",
       "                                              learning_rate=&#x27;adaptive&#x27;,\n",
       "                                              loss=&#x27;log_loss&#x27;, n_jobs=8,\n",
       "                                              random_state=2023),\n",
       "                      n_jobs=10)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultiOutputClassifier</label><div class=\"sk-toggleable__content\"><pre>MultiOutputClassifier(estimator=SGDClassifier(eta0=0.0001,\n",
       "                                              learning_rate=&#x27;adaptive&#x27;,\n",
       "                                              loss=&#x27;log_loss&#x27;, n_jobs=8,\n",
       "                                              random_state=2023),\n",
       "                      n_jobs=10)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: SGDClassifier</label><div class=\"sk-toggleable__content\"><pre>SGDClassifier(eta0=0.0001, learning_rate=&#x27;adaptive&#x27;, loss=&#x27;log_loss&#x27;, n_jobs=8,\n",
       "              random_state=2023)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SGDClassifier</label><div class=\"sk-toggleable__content\"><pre>SGDClassifier(eta0=0.0001, learning_rate=&#x27;adaptive&#x27;, loss=&#x27;log_loss&#x27;, n_jobs=8,\n",
       "              random_state=2023)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "MultiOutputClassifier(estimator=SGDClassifier(eta0=0.0001,\n",
       "                                              learning_rate='adaptive',\n",
       "                                              loss='log_loss', n_jobs=8,\n",
       "                                              random_state=2023),\n",
       "                      n_jobs=10)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mclf.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_index(preds):\n",
    "    types = preds[0]\n",
    "    grades = preds[1]\n",
    "    max_grade = -1\n",
    "    max_type = -1\n",
    "    max_index = -1\n",
    "\n",
    "    for i in range(len(preds[0])):\n",
    "        t = types[i]\n",
    "        g = grades[i]\n",
    "        if t > max_type or (t == max_type and g > max_grade):\n",
    "            max_type = t\n",
    "            max_grade = g\n",
    "            max_index = i\n",
    "    return max_index\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_majority_index(preds):\n",
    "    types = preds[0]\n",
    "    grades = preds[1]\n",
    "    type_counts = [0,0,0]\n",
    "    grade_counts = [0,0,0]\n",
    "    for i in range(len(types)):\n",
    "        type_counts[types[i]] += 1\n",
    "        grade_counts[grades[i]] += 1\n",
    "    max_type = type_counts.index(max(type_counts))\n",
    "    max_grade = grade_counts.index(max(grade_counts))\n",
    "    for i in range(len(types)):\n",
    "        if types[i] == max_type and grades[i] == max_grade:\n",
    "            return i\n",
    "    return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bcnb abmil type acc: 0.9698, auc: nan [nan nan nan]\n",
      "bcnb abmil ibc acc: 0.5238, auc: 0.6634 [0.7236 0.5962 0.6707]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# testing\n",
    "pha='test'\n",
    "# test_cohorts = ['suqh_all_patch', 'qduh', 'shsu', 'bracs', 'bcnb', 'bach', 'apght']\n",
    "test_cohorts = [ 'suqh_all_patch']\n",
    "# load_dir = Path('/mnt/hd0/project/bcacad/model/roi_models/model2')\n",
    "for cohort in test_cohorts:\n",
    "    for model_name in model_names:\n",
    "        # model = get_model(model_name, input_dim, out_dim).to(device)\n",
    "        model = models[model_name]\n",
    "        # ckpt = torch.load(load_dir / f'{model_name}.pth')\n",
    "        # model.load_state_dict(ckpt)\n",
    "        # model = model.to(device)\n",
    "        wsi_dirs = list((feature_root / cohort / 'test').glob('*/*'))\n",
    "        test_sets = [Feature(wsi_dir, 'test') for wsi_dir in wsi_dirs]\n",
    "        # test_set = FeatureWSI(feature_root / cohort / 'test', 'test')\n",
    "        # trainer = TorchTrainer(model, criterion, merics, device=device, num_epochs=50)\n",
    "        Labels =[[],[]]\n",
    "        Preds = [[],[]]\n",
    "        Probs = [[],[]]\n",
    "        for test_set in test_sets:\n",
    "            res = trainer.predict(test_set)\n",
    "\n",
    "            labels = np.array(res[0])\n",
    "            probs = np.array(res[1])\n",
    "            preds = np.array(res[2])\n",
    "            max_idx = get_max_index(preds)\n",
    "            # max_idx = get_majority_index(preds)\n",
    "            label = labels[0][max_idx], labels[1][max_idx]\n",
    "            prob = probs[0][max_idx], probs[1][max_idx]\n",
    "            pred = preds[0][max_idx], preds[1][max_idx]\n",
    "            Labels[0].append(label[0])\n",
    "            Labels[1].append(label[1])\n",
    "            Probs[0].append(prob[0])\n",
    "            Probs[1].append(prob[1])\n",
    "            Preds[0].append(pred[0])\n",
    "            Preds[1].append(pred[1])\n",
    "\n",
    "        \n",
    "        labels = np.array(Labels)\n",
    "        probs = np.array(Probs)\n",
    "        preds = np.array(Preds)\n",
    "            \n",
    "\n",
    "        type_labels = labels[0]\n",
    "        type_probs = probs[0]\n",
    "        type_preds = preds[0]\n",
    "\n",
    "        nonibc_index = np.where(type_labels ==1)\n",
    "        nonibc_labels = labels[1][nonibc_index]\n",
    "        nonibc_probs = probs[1][nonibc_index]\n",
    "        nonibc_preds = preds[1][nonibc_index]\n",
    "\n",
    "        ibc_index = np.where(type_labels ==2)\n",
    "        ibc_labels = labels[1][ibc_index]\n",
    "        ibc_probs = probs[1][ibc_index]\n",
    "        ibc_preds = preds[1][ibc_index]\n",
    "\n",
    "        re = {}\n",
    "        avg_aucs = {}\n",
    "        if type_labels.size == 0:\n",
    "            re['type'] = None\n",
    "            avg_aucs['type'] = None\n",
    "        else:\n",
    "            re['type'] = report(type_labels, type_preds, type_probs, class_names['type'])\n",
    "            avg_aucs['type'] = compute_mean_one_vs_all_auc(type_labels, type_probs)\n",
    "\n",
    "        if nonibc_labels.size == 0:\n",
    "            re['nonibc'] = None\n",
    "            avg_aucs['nonibc'] = None\n",
    "        else:\n",
    "            re['nonibc'] = report(nonibc_labels, nonibc_preds, nonibc_probs, class_names['nonibc'])\n",
    "            avg_aucs['nonibc'] = compute_mean_one_vs_all_auc(nonibc_labels, nonibc_probs)\n",
    "\n",
    "        if ibc_labels.size == 0:\n",
    "            re['ibc'] = None\n",
    "            avg_aucs['ibc'] = None\n",
    "        else:\n",
    "            re['ibc'] = report(ibc_labels, ibc_preds, ibc_probs, class_names['ibc'])\n",
    "            avg_aucs['ibc'] = compute_mean_one_vs_all_auc(ibc_labels, ibc_probs)\n",
    "\n",
    "        for task in ['type', 'nonibc', 'ibc']:\n",
    "            r = re[task]\n",
    "            if r is None:\n",
    "                continue\n",
    "            fs = \"{} {} {} acc: {:.4f}, auc: {:.4f} [{:.4f} {:.4f} {:.4f}]\".format(cohort, model_name, task, r['accuracy'], avg_aucs[task], r['0']['auc'], r['1']['auc'], r['2']['auc'])\n",
    "            print(fs)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save abmil.pth\n",
      "save transmil.pth\n"
     ]
    }
   ],
   "source": [
    "save_root = Path('/mnt/hd0/project/bcacad/model/roi_models/model7')\n",
    "if not save_root.exists():\n",
    "    save_root.mkdir()\n",
    "for model_name in model_names:\n",
    "    torch.save(models[model_name].state_dict(), save_root / f'{model_name}.pth')\n",
    "    print(f'save {model_name}.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = FeatureWSI(feature_root / cohort / 'test', 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_set.features[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36, 768)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.concatenate(test_set.features[3], axis=0).shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "histosslscaling",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
