{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "Image.MAX_IMAGE_PIXELS = None\n",
    "from torchvision import transforms\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import os\n",
    "from multiprocessing import Pool\n",
    "# import umap\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision import transforms\n",
    "\n",
    "from sklearn.metrics import f1_score, precision_recall_fscore_support, roc_auc_score, confusion_matrix, cohen_kappa_score, accuracy_score\n",
    "import torch.nn.functional as F\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "# import albumentations as A\n",
    "# from albumentations.pytorch import ToTensorV2\n",
    "import cv2\n",
    "import time\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "import timm\n",
    "from metrics import report\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader, Subset, Dataset\n",
    "from tqdm import tqdm\n",
    "from rl_benchmarks.metrics import *\n",
    "from pathlib import Path\n",
    "from rl_benchmarks.trainers.torch_trainer import TorchTrainer\n",
    "from rl_benchmarks.models.slide_models.meanpool import MeanPool\n",
    "from rl_benchmarks.models.slide_models.chowder import Chowder\n",
    "from rl_benchmarks.models.slide_models.dsmil import DSMIL\n",
    "from rl_benchmarks.models.slide_models.abmil import ABMIL\n",
    "from rl_benchmarks.models.slide_models.hiptmil import HIPTMIL\n",
    "from rl_benchmarks.models.slide_models.transmil import TransMIL\n",
    "\n",
    "import sys\n",
    "sys.path.append('/home/yuxin/bme/BCaCAD/model')\n",
    "from patch_based_test.img import QiLuROI\n",
    "\n",
    "def get_model(model_name, in_dim, out_dim):\n",
    "    if model_name == 'abmil':\n",
    "        model = ABMIL(in_dim, out_dim, d_model_attention=128,temperature= 1.0, mlp_hidden= [128, 64])\n",
    "    elif model_name == 'chowder':\n",
    "        model = Chowder(in_dim, out_dim, n_top= 2,n_bottom= 2,tiles_mlp_hidden= [128], mlp_hidden= [128, 64])\n",
    "    elif model_name == 'dsmil':\n",
    "        model = DSMIL(in_dim, out_dim, d_tiles_values= 32,d_tiles_queries= 32,passing_values= False,tiles_scores_mlp_hidden=[200,100],\n",
    "                        tiles_queries_mlp_hidden=[200,100], mlp_hidden=[200,100])\n",
    "    elif model_name == 'hiptmil':\n",
    "        model = HIPTMIL(in_dim, out_dim)\n",
    "    elif model_name == 'transmil':\n",
    "        model = TransMIL(in_dim, out_features=out_dim)\n",
    "    elif model_name == 'meanpool':\n",
    "        model = MeanPool(in_dim, out_dim)\n",
    "    else:\n",
    "        raise 'model not found'\n",
    "    return model\n",
    "input_dim = 768\n",
    "out_dim = [3,3]\n",
    "import torch\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = [ 'abmil']\n",
    "models={}\n",
    "model_dir = Path('/mnt/hd0/project/bcacad/model/roi_models/model6')\n",
    "for model_name in model_names:\n",
    "    model = get_model(model_name, input_dim, out_dim).to(device)\n",
    "    model.load_state_dict(torch.load(model_dir / f'{model_name}.pth'))\n",
    "    models[model_name] = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 6, 768])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "path = '/mnt/hd0/project/bcacad/model/roi_features/suqh_all_patch/test/dcis-2/01594.17-2-10x-x33298-y39454-w2091-h2988-dcis-2.png.npy'\n",
    "features = torch.from_numpy(np.load(path)).to(device)\n",
    "features = features.unsqueeze(0)\n",
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 128])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roi_feats = model.extract_features(features)\n",
    "roi_feats.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "roi_model = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WSI(Dataset):\n",
    "    def get_label(self, type):\n",
    "        D = {\n",
    "            'normal':[0,0],\n",
    "            'dcis-1':[1,0],\n",
    "            'dcis-2':[1,1],\n",
    "            'dcis-3':[1,2],\n",
    "            'ibc-1':[2,0],\n",
    "            'ibc-2':[2,1],\n",
    "            'ibc-3':[2,2],\n",
    "        }\n",
    "        label =  D[type]\n",
    "        return label[0],label[1]\n",
    "    \n",
    "    def __init__(self, feature_dir, phase='test'):\n",
    "        folder = Path(feature_dir)\n",
    "        wsi_dirs = list(folder.glob('*/*'))\n",
    "        # self.labels = [self.get_label(path.parent.name) for path in wsi_dirs]\n",
    "        self.labels = []\n",
    "        for path in wsi_dirs:\n",
    "            label = path.parent.name\n",
    "            cvtlabel = self.get_label(label)\n",
    "            self.labels.append(cvtlabel)\n",
    "        # self.features = [np.load(path) for path in feature_paths]\n",
    "        self.features = []\n",
    "        for wsi_dir in wsi_dirs:\n",
    "            feature_paths = list(wsi_dir.rglob('**/*.npy'))\n",
    "            features = []\n",
    "            for path in feature_paths:\n",
    "                patch_features = torch.from_numpy(np.load(path)).to(device).unsqueeze(0)\n",
    "                roi_feats = roi_model.extract_features(patch_features)\n",
    "                features.append(roi_feats)\n",
    "            self.features.append(features)\n",
    "        self.wsis = wsi_dirs\n",
    "        self.phase=phase\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.wsis)\n",
    "    def __getitem__(self, item):\n",
    "        features = self.features[item]\n",
    "        # wsi = self.wsis[item]\n",
    "        if self.phase == 'train':\n",
    "            indices = np.random.choice(len(features), 6, replace=True)\n",
    "            features = torch.cat([features[i] for i in indices], dim=0)\n",
    "            return features, self.labels[item]\n",
    "        features = torch.cat(features, dim=0)\n",
    "        return features, self.labels[item]\n",
    "    \n",
    "    @staticmethod\n",
    "    def collate_fn(batch):\n",
    "        # 官方实现的default_collate可以参考\n",
    "        # https://github.com/pytorch/pytorch/blob/67b7e751e6b5931a9f45274653f4f653a4e6cdf6/torch/utils/data/_utils/collate.py\n",
    "        images,  labels = tuple(zip(*batch))\n",
    "\n",
    "        images = torch.stack(images, dim=0)\n",
    "        labels = torch.as_tensor(labels)\n",
    "        # masks = torch.as_tensor(masks)\n",
    "\n",
    "        return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = dict(\n",
    "    epoch=200,\n",
    "    bs=8,\n",
    "    # train_tiles = 4,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "merics = {'acc': compute_multiclass_accuracy, 'auc': compute_mean_one_vs_all_auc}\n",
    "input_dim = 128\n",
    "out_dim = [3,3]\n",
    "tasks = ['type', 'nonibc', 'ibc']\n",
    "class_names = {\n",
    "    'type': ['Normal', 'nonIBC', 'IBC'],\n",
    "    'nonibc': ['Low', 'Medium', 'High'],\n",
    "    'ibc': ['Low', 'Medium', 'High'],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_root = Path('/mnt/hd0/project/bcacad/model/wsi_features')\n",
    "train_set = WSI(feature_root / 'suqh_all_patch' / 'model', 'train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 128])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [18:46<00:00,  5.63s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abmil train type acc: 0.9818, auc: 0.9977 [0.9995 0.9956 0.9983]\n",
      "abmil train nonibc acc: 0.9108, auc: 0.9695 [0.9744 0.9541 0.9810]\n",
      "abmil train ibc acc: 0.9311, auc: 0.9809 [0.9899 0.9734 0.9794]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_names = [ 'abmil']\n",
    "\n",
    "models={}\n",
    "for model_name in model_names:\n",
    "    # print(model_name)\n",
    "    model = get_model(model_name, input_dim, out_dim).to(device)\n",
    "    trainer = TorchTrainer(model, criterion, merics, device=device, num_epochs=cfg['epoch'], batch_size=cfg['bs'])\n",
    "    res = trainer.train(train_set, train_set)\n",
    "    # res = trainer.train(fake, fake)\n",
    "    models[model_name] = model\n",
    "\n",
    "\n",
    "    pha = 'train'\n",
    "    labels = np.array(res[pha][0])\n",
    "    probs = np.array(res[pha][1])\n",
    "    preds = np.array(res[pha][2])\n",
    "\n",
    "    type_labels = labels[0]\n",
    "    type_probs = probs[0]\n",
    "    type_preds = preds[0]\n",
    "\n",
    "    nonibc_index = np.where(type_labels ==1)\n",
    "    nonibc_labels = labels[1][nonibc_index]\n",
    "    nonibc_probs = probs[1][nonibc_index]\n",
    "    nonibc_preds = preds[1][nonibc_index]\n",
    "\n",
    "    ibc_index = np.where(type_labels ==2)\n",
    "    ibc_labels = labels[1][ibc_index]\n",
    "    ibc_probs = probs[1][ibc_index]\n",
    "    ibc_preds = preds[1][ibc_index]\n",
    "\n",
    "    re = {}\n",
    "    avg_aucs = {}\n",
    "    re['type'] = report(type_labels, type_preds, type_probs, class_names['type'])\n",
    "    avg_aucs['type'] = compute_mean_one_vs_all_auc(type_labels, type_probs)\n",
    "\n",
    "    re['nonibc'] = report(nonibc_labels, nonibc_preds, nonibc_probs, class_names['nonibc'])\n",
    "    avg_aucs['nonibc'] = compute_mean_one_vs_all_auc(nonibc_labels, nonibc_probs)\n",
    "\n",
    "    re['ibc'] = report(ibc_labels, ibc_preds, ibc_probs, class_names['ibc'])\n",
    "    avg_aucs['ibc'] = compute_mean_one_vs_all_auc(ibc_labels, ibc_probs)\n",
    "\n",
    "    for task in ['type', 'nonibc', 'ibc']:\n",
    "        r = re[task]\n",
    "        fs = \"{} {} {} acc: {:.4f}, auc: {:.4f} [{:.4f} {:.4f} {:.4f}]\".format(model_name, pha, task, r['accuracy'], avg_aucs[task], r['0']['auc'], r['1']['auc'], r['2']['auc'])\n",
    "        print(fs)\n",
    "    print()\n",
    "print()\n",
    "    \n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save abmil.pth\n"
     ]
    }
   ],
   "source": [
    "save_root = Path('/mnt/hd0/project/bcacad/model/wsi_models/model1')\n",
    "if not save_root.exists():\n",
    "    save_root.mkdir(parents=True)\n",
    "for model_name in model_names:\n",
    "    torch.save(models[model_name].state_dict(), save_root / f'{model_name}.pth')\n",
    "    print(f'save {model_name}.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = [ 'abmil']\n",
    "models={}\n",
    "model_dir = Path('/mnt/hd0/project/bcacad/model/wsi_models/model1')\n",
    "for model_name in model_names:\n",
    "    model = get_model(model_name, input_dim, out_dim).to(device)\n",
    "    model.load_state_dict(torch.load(model_dir / f'{model_name}.pth'))\n",
    "    models[model_name] = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "suqh_all_patch abmil type acc: 0.9733, auc: 0.9927 [0.9982 0.9898 0.9891]\n",
      "suqh_all_patch abmil nonibc acc: 0.5000, auc: 0.6800 [0.6514 0.6038 0.7903]\n",
      "suqh_all_patch abmil ibc acc: 0.6842, auc: 0.7902 [0.8734 0.6859 0.8100]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# testing\n",
    "pha='test'\n",
    "# test_cohorts = ['suqh_all_patch', 'qduh', 'shsu', 'bracs', 'bcnb', 'bach', 'apght']\n",
    "test_cohorts = [ 'suqh_all_patch']\n",
    "# load_dir = Path('/mnt/hd0/project/bcacad/model/roi_models/model2')\n",
    "for cohort in test_cohorts:\n",
    "    for model_name in model_names:\n",
    "        # model = get_model(model_name, input_dim, out_dim).to(device)\n",
    "        model = models[model_name]\n",
    "        # ckpt = torch.load(load_dir / f'{model_name}.pth')\n",
    "        # model.load_state_dict(ckpt)\n",
    "        # model = model.to(device)\n",
    "\n",
    "        test_set = WSI(feature_root / cohort / 'test', 'test')\n",
    "        trainer = TorchTrainer(model, criterion, merics, device=device, num_epochs=50)\n",
    "        res = trainer.predict(test_set)\n",
    "\n",
    "        labels = np.array(res[0])\n",
    "        probs = np.array(res[1])\n",
    "        preds = np.array(res[2])\n",
    "\n",
    "        type_labels = labels[0]\n",
    "        type_probs = probs[0]\n",
    "        type_preds = preds[0]\n",
    "\n",
    "        nonibc_index = np.where(type_labels ==1)\n",
    "        nonibc_labels = labels[1][nonibc_index]\n",
    "        nonibc_probs = probs[1][nonibc_index]\n",
    "        nonibc_preds = preds[1][nonibc_index]\n",
    "\n",
    "        ibc_index = np.where(type_labels ==2)\n",
    "        ibc_labels = labels[1][ibc_index]\n",
    "        ibc_probs = probs[1][ibc_index]\n",
    "        ibc_preds = preds[1][ibc_index]\n",
    "\n",
    "        re = {}\n",
    "        avg_aucs = {}\n",
    "        if type_labels.size == 0:\n",
    "            re['type'] = None\n",
    "            avg_aucs['type'] = None\n",
    "        else:\n",
    "            re['type'] = report(type_labels, type_preds, type_probs, class_names['type'])\n",
    "            avg_aucs['type'] = compute_mean_one_vs_all_auc(type_labels, type_probs)\n",
    "\n",
    "        if nonibc_labels.size == 0:\n",
    "            re['nonibc'] = None\n",
    "            avg_aucs['nonibc'] = None\n",
    "        else:\n",
    "            re['nonibc'] = report(nonibc_labels, nonibc_preds, nonibc_probs, class_names['nonibc'])\n",
    "            avg_aucs['nonibc'] = compute_mean_one_vs_all_auc(nonibc_labels, nonibc_probs)\n",
    "\n",
    "        if ibc_labels.size == 0:\n",
    "            re['ibc'] = None\n",
    "            avg_aucs['ibc'] = None\n",
    "        else:\n",
    "            re['ibc'] = report(ibc_labels, ibc_preds, ibc_probs, class_names['ibc'])\n",
    "            avg_aucs['ibc'] = compute_mean_one_vs_all_auc(ibc_labels, ibc_probs)\n",
    "\n",
    "        for task in ['type', 'nonibc', 'ibc']:\n",
    "            r = re[task]\n",
    "            if r is None:\n",
    "                continue\n",
    "            fs = \"{} {} {} acc: {:.4f}, auc: {:.4f} [{:.4f} {:.4f} {:.4f}]\".format(cohort, model_name, task, r['accuracy'], avg_aucs[task], r['0']['auc'], r['1']['auc'], r['2']['auc'])\n",
    "            print(fs)\n",
    "        print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "histosslscaling",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
